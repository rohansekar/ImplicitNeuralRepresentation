{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from SSIM_PIL import compare_ssim\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2=plt.imread(r'C:\\Users\\rohan\\Downloads\\Miniproject (2)\\Miniproject\\data\\image\\fox.jpg')\n",
    "image1=np.load(r\"C:\\Users\\rohan\\Downloads\\Miniproject (2)\\Miniproject\\data\\radon\\fox.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nradon_transform(img):\n",
    "    store = []\n",
    "    for degree in range(360):\n",
    "        rot= torchvision.transforms.functional.rotate(img.permute(2, 0, 1), degree)\n",
    "        c = torch.exp(-0.01 * torch.cumsum(rot, 1))\n",
    "        integral = torch.sum(rot * c, 1, keepdim=True)\n",
    "        store.append(integral)\n",
    "    r= torch.stack(store, 1).permute(2, 3, 1, 0)[0]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 180, 3)\n",
      "(262144, 2)\n"
     ]
    }
   ],
   "source": [
    "print(image1.shape)\n",
    "x,y=np.meshgrid(np.linspace(0,1,512),np.linspace(0,1,512))\n",
    "x=x.reshape((512*512),1)\n",
    "y=y.reshape((512*512),1)\n",
    "pixels=np.hstack((x,y))\n",
    "pixels=torch.Tensor(pixels)\n",
    "transforms=torchvision.transforms.ToTensor()\n",
    "image1=transforms(image1)\n",
    "print(pixels.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(est,gt):\n",
    "    psnr =-20*np.log10(np.linalg.norm((gt-est).reshape(-1))/(np.sqrt(gt.size)*np.max(gt)))\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Implicit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Implicit, self).__init__()\n",
    "        self.linear1=nn.Linear(2,128)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.linear2=nn.Linear(128,256)\n",
    "        self.linear3=nn.Linear(256,512)\n",
    "        self.linear4=nn.Linear(512,512)\n",
    "        self.linear5=nn.Linear(512,256)\n",
    "        self.linear6=nn.Linear(256,128)\n",
    "        self.linear7=nn.Linear(128,64)\n",
    "        self.linear8=nn.Linear(64,32)\n",
    "        self.linear9=nn.Linear(32,3)\n",
    "        self.a=nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        x=self.linear1(x)\n",
    "        x=self.relu1(x)\n",
    "        x=self.linear2(x)\n",
    "        x=self.relu1(x)\n",
    "        x=self.linear3(x)\n",
    "        x=self.relu1(x)\n",
    "        x=self.linear4(x)\n",
    "        x=self.relu1(x)\n",
    "        x=self.linear5(x)\n",
    "        x=self.relu1(x)\n",
    "        x=self.linear6(x)\n",
    "        x=self.relu1(x)\n",
    "        x=self.linear7(x)\n",
    "        x=self.relu1(x)\n",
    "        x=self.linear8(x)\n",
    "        x=self.relu1(x)\n",
    "        x=self.linear9(x)\n",
    "        x=self.a(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 20712.425781\n",
      "No module named 'pyopencl'\n",
      "Epoch: 1 \tTraining Loss: 20697.410156\n",
      "No module named 'pyopencl'\n",
      "Epoch: 2 \tTraining Loss: 20682.394531\n",
      "No module named 'pyopencl'\n",
      "Epoch: 3 \tTraining Loss: 20665.660156\n",
      "No module named 'pyopencl'\n",
      "Epoch: 4 \tTraining Loss: 20642.875000\n",
      "No module named 'pyopencl'\n",
      "Epoch: 5 \tTraining Loss: 20613.515625\n",
      "No module named 'pyopencl'\n",
      "Epoch: 6 \tTraining Loss: 20577.650391\n",
      "No module named 'pyopencl'\n",
      "Epoch: 7 \tTraining Loss: 20521.330078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 8 \tTraining Loss: 20428.253906\n",
      "No module named 'pyopencl'\n",
      "Epoch: 9 \tTraining Loss: 20282.945312\n",
      "No module named 'pyopencl'\n",
      "Epoch: 10 \tTraining Loss: 20084.054688\n",
      "No module named 'pyopencl'\n",
      "Epoch: 11 \tTraining Loss: 19853.371094\n",
      "No module named 'pyopencl'\n",
      "Epoch: 12 \tTraining Loss: 19615.300781\n",
      "No module named 'pyopencl'\n",
      "Epoch: 13 \tTraining Loss: 19411.115234\n",
      "No module named 'pyopencl'\n",
      "Epoch: 14 \tTraining Loss: 19265.982422\n",
      "No module named 'pyopencl'\n",
      "Epoch: 15 \tTraining Loss: 19182.416016\n",
      "No module named 'pyopencl'\n",
      "Epoch: 16 \tTraining Loss: 19145.253906\n",
      "No module named 'pyopencl'\n",
      "Epoch: 17 \tTraining Loss: 19133.412109\n",
      "No module named 'pyopencl'\n",
      "Epoch: 18 \tTraining Loss: 19130.718750\n",
      "No module named 'pyopencl'\n",
      "Epoch: 19 \tTraining Loss: 19130.267578\n",
      "No module named 'pyopencl'\n",
      "Epoch: 20 \tTraining Loss: 19130.212891\n",
      "No module named 'pyopencl'\n",
      "Epoch: 21 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 22 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 23 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 24 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 25 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 26 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 27 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 28 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 29 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 30 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 31 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 32 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 33 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 34 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 35 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 36 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 37 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 38 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 39 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 40 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 41 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 42 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 43 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 44 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 45 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 46 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 47 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 48 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 49 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 50 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 51 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 52 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 53 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 54 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 55 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 56 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 57 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 58 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 59 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 60 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 61 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 62 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 63 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 64 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 65 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 66 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 67 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 68 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 69 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 70 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 71 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 72 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 73 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 74 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 75 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 76 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 77 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 78 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 79 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 80 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 81 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 82 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 83 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 84 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 85 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 86 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 87 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 88 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 89 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 90 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 91 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 92 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 93 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n",
      "Epoch: 94 \tTraining Loss: 19130.205078\n",
      "No module named 'pyopencl'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rohan\\Desktop\\IDL Mini-Project\\IDL Mini-Project 4.ipynb Cell 8\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/IDL%20Mini-Project/IDL%20Mini-Project%204.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m image1\u001b[39m=\u001b[39mimage1\u001b[39m.\u001b[39mreshape(\u001b[39m512\u001b[39m,\u001b[39m180\u001b[39m,\u001b[39m3\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/IDL%20Mini-Project/IDL%20Mini-Project%204.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m loss\u001b[39m=\u001b[39mcriterion(newoutput,image1)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/IDL%20Mini-Project/IDL%20Mini-Project%204.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/IDL%20Mini-Project/IDL%20Mini-Project%204.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/IDL%20Mini-Project/IDL%20Mini-Project%204.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m trainlosstrack\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\rohan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\rohan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "implicit=Implicit()\n",
    "implicit.to(device)\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(implicit.parameters(),lr = 0.001)\n",
    "n_epochs=10000\n",
    "x=pixels\n",
    "train_loss = 0\n",
    "epochtrack=[]\n",
    "psnrtrack=[]\n",
    "simtrack=[]\n",
    "trainlosstrack=[]\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    out=implicit(x.to(device))\n",
    "    out=out.reshape(3,512,512)\n",
    "    newoutput=nradon_transform(out.to(device),180)\n",
    "    newoutput=newoutput.reshape(512,180,3)\n",
    "    image1=image1.reshape(512,180,3)\n",
    "    loss=criterion(newoutput,image1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    trainlosstrack.append(loss.item())\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, loss.item()))\n",
    "    newoutput=newoutput.reshape(512,180,3)\n",
    "    image1=image1.reshape(512,180,3)\n",
    "    image2.reshape(512,512,3)\n",
    "    psnrvalue=psnr(out.cpu().detach().numpy().reshape(512,512,3),image2)\n",
    "    psnrtrack.append(psnrvalue)\n",
    "    value = compare_ssim(Image.fromarray((out.cpu().detach().numpy().reshape(512,512,3)*255).astype(np.uint8)),Image.fromarray((image2*255).astype(np.uint8)))\n",
    "    simtrack.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainlosstrack)\n",
    "plt.plot(psnrtrack)\n",
    "plt.title('PSNR vs Epochs')\n",
    "plt.show()\n",
    "plt.plot(simtrack)\n",
    "plt.title('SSIM vs Epochs')\n",
    "plt.show()\n",
    "out=implicit(pixels)\n",
    "plt.imshow(out.reshape(512,180,1).detach().numpy())\n",
    "plt.show()\n",
    "plt.imshow(image1)\n",
    "plt.show()\n",
    "image1=image1.reshape(512*180*1)\n",
    "out=out.reshape(512*180*1)\n",
    "print(out.shape)\n",
    "print(image1.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
